xreg=NULL # default covariates
xreg_pred=NULL # default covariates for predictions
for (i in seq(0,length(test)-hor,hor)){ # for each window of observations in test set
train_ts<-ts(c(train,test[seq_len(i)]),frequency=freq) # add new observations from test set to the current train set
if (!is.null(xreg_train)&!is.null(xreg_test)){ # if considering external regressors
xreg<-rbind(xreg_train,xreg_test[seq_len(i),]) # add covariates corresponding to new observations
xreg_pred<-xreg_test[i+seq_len(hor),] # add covariates for predictions
}
if (i%%(batch*hor)==0){ # if its time to retrain
bc_lambda<-if (box_cox) BoxCox.lambda(train,method='') else NULL # estimate lambda for Box-Cox transformation
if (dec){ # if decomposition is to be applied
model<-stlm(train_ts,method='arima',xreg=xreg,s.window='periodic',robust=TRUE,parallel = TRUE,stepwise=FALSE,lambda=bc_lambda,biasadj = FALSE) # find best model on the current train set
cat(i%/%(batch*hor),arimaorder(model$model),'\n') # print number of retrainings and the type of model
}
else { # no decomposition
model<-auto.arima(train_ts,xreg=xreg,parallel = TRUE,stepwise=FALSE,lambda=bc_lambda,biasadj = FALSE) # find best model on the current train set
cat(i%/%(batch*hor),arimaorder(model),'\n') # print number of retrainings and the type of model
}
}
else{ # it is not the time to retrain
if (dec){
model<-stlm(train_ts,model=model,xreg=xreg,s.window='periodic',robust=TRUE,parallel = TRUE,stepwise=FALSE,lambda=bc_lambda,biasadj = FALSE) # do not train, use current model with new observations
cat(i%/%(batch*hor),arimaorder(model$model),'\n') # print number of retrainings and the type of model
}
else
{
model<-Arima(train_ts,model=model,xreg=xreg,lambda=bc_lambda,biasadj=FALSE) # do not train, use current model with new observations
cat(i%/%(batch*hor),arimaorder(model),'\n') # print number of retrainings and the type of model
}
}
test_pred[(i%/%hor)+1,]<-forecast(model,h=hor,lambda=bc_lambda,biasadj=FALSE)$mean # predict new values
}
return(test_pred)
}
arima_h<-function(train,test,batch=7,freq=48,f_K=NULL,wxreg_train=NULL,wxreg_test=NULL,box_cox=FALSE,dec=FALSE){
return(arima(train,test,hor=48,batch=batch,freq=freq,f_K=f_K,wxreg_train=wxreg_train,wxreg_test=wxreg_test,box_cox = box_cox,dec = dec))
}
arima_v<-function(train,test,batch=7,freq=7,f_K=NULL,wxreg_train=NULL,wxreg_test=NULL,box_cox=FALSE,dec=FALSE){
test_pred<-data.frame(matrix(data=NA,nrow=nrow(test),ncol=ncol(test),dimnames=list(rownames(test),colnames(test))),check.names = FALSE) # initialize dataframe for predictions
for (col in names(train)){
train_day<-as.data.frame(train[[col]],row.names=rownames(train)) # convert dataframe column to dataframe
test_day<-as.data.frame(test[[col]],row.names=rownames(test)) # convert dataframe column to dataframe
colnames(train_day)<-c(col) # set column name to match
colnames(test_day)<-c(col) # set column name to match
if (is.null(wxreg_train)|is.null(wxreg_test))
{
wxreg_train_day<-NULL
wxreg_test_day<-NULL
}
else
{
wxreg_train_day<-lapply(wxreg_train,function(x) as.data.frame(`[[`(x, col))) # extract a particular column from each member of list of covariates
wxreg_test_day<-lapply(wxreg_test,function(x) as.data.frame(`[[`(x, col))) # extract a particular column from each member of list of covariates
}
test_pred[[col]]<-arima(train_day,test_day,hor=1,batch=batch,freq=freq,f_K=f_K,wxreg_train=wxreg_train_day,wxreg_test=wxreg_test_day)[[col]] # predictions
}
return(test_pred)
}
data_dir<-'C:/Users/SABA/Google Drive/mtsg/data/nocb/arima/data' # directory containing data
exp_dir<-'C:/Users/SABA/Google Drive/mtsg/data/nocb/arima/exp' # directory for the results of experiments
train<-load(paste(data_dir,'train.csv', sep='')) # load train set
test<-load(paste(data_dir,'test.csv', sep='')) # load test set
data_dir<-'C:/Users/SABA/Google Drive/mtsg/data/nocb/arima/data/' # directory containing data
exp_dir<-'C:/Users/SABA/Google Drive/mtsg/data/nocb/arima/exp/' # directory for the results of experiments
train<-load(paste(data_dir,'train.csv', sep='')) # load train set
test<-load(paste(data_dir,'test.csv', sep='')) # load test set
arima<-function(train,test,hor=1,batch=7,freq=24,f_K=NULL,wxreg_train=NULL,wxreg_test=NULL,box_cox=FALSE,dec=FALSE){
test_pred<-data.frame(matrix(data=NA,nrow=nrow(test),ncol=ncol(test),dimnames=list(rownames(test),colnames(test))),check.names = FALSE) # initialize matrix for predictions
train<-c(t(train)) # flatten train set
test<-c(t(test)) # flatten test set
if (is.null(f_K)){ # not considering multiple seasonalities
fxreg_train<-NULL
fxreg_test<-NULL
}
else { # considering multiple seasonalities
fxreg_train<-fourier(msts(train,seasonal.periods=freqs),K=f_K)
fxreg_test<-fourier(msts(test,seasonal.periods=freqs),K=f_K)
}
if (is.null(wxreg_train)|is.null(wxreg_test)) # not considering weather regressors
{
wxreg_train<-NULL
wxreg_test<-NULL
}
else{ # considering weather regressors
wxreg_train<-do.call(cbind,lapply(wxreg_train,function(x) c(t(x)))) # flatten and combine weather regressors for train set
wxreg_test<-do.call(cbind,lapply(wxreg_test,function(x) c(t(x)))) # flatten and combine weather regressors for test set
}
xreg_train<-cbind(fxreg_train,wxreg_train) # combine fourier & weather into one matrix for train set
xreg_test<-cbind(fxreg_test,wxreg_test) # combine fourier & weather into one matrix for test set
xreg=NULL # default covariates
xreg_pred=NULL # default covariates for predictions
for (i in seq(0,length(test)-hor,hor)){ # for each window of observations in test set
train_ts<-ts(c(train,test[seq_len(i)]),frequency=freq) # add new observations from test set to the current train set
if (!is.null(xreg_train)&!is.null(xreg_test)){ # if considering external regressors
xreg<-rbind(xreg_train,xreg_test[seq_len(i),]) # add covariates corresponding to new observations
xreg_pred<-xreg_test[i+seq_len(hor),] # add covariates for predictions
}
if (i%%(batch*hor)==0){ # if its time to retrain
bc_lambda<-if (box_cox) BoxCox.lambda(train,method='') else NULL # estimate lambda for Box-Cox transformation
if (dec){ # if decomposition is to be applied
model<-stlm(train_ts,method='arima',xreg=xreg,s.window='periodic',robust=TRUE,parallel = TRUE,stepwise=FALSE,lambda=bc_lambda,biasadj = FALSE) # find best model on the current train set
cat(i%/%(batch*hor),arimaorder(model$model),'\n') # print number of retrainings and the type of model
}
else { # no decomposition
model<-auto.arima(train_ts,xreg=xreg,parallel = TRUE,stepwise=FALSE,lambda=bc_lambda,biasadj = FALSE) # find best model on the current train set
cat(i%/%(batch*hor),arimaorder(model),'\n') # print number of retrainings and the type of model
}
}
else{ # it is not the time to retrain
if (dec){
model<-stlm(train_ts,model=model,xreg=xreg,s.window='periodic',robust=TRUE,parallel = TRUE,stepwise=FALSE,lambda=bc_lambda,biasadj = FALSE) # do not train, use current model with new observations
}
else
{
model<-Arima(train_ts,model=model,xreg=xreg,lambda=bc_lambda,biasadj=FALSE) # do not train, use current model with new observations
}
}
test_pred[(i%/%hor)+1,]<-forecast(model,h=hor,lambda=bc_lambda,biasadj=FALSE)$mean # predict new values
}
return(test_pred)
}
library(forecast)
source('dataprep.R')
pop_col=function(data,col){ # removes and returns column from dataframe
poped_col<-data$col # extract column from dataframe
data<<-data[ , !names(data) %in% c(col)] # drop column from dataframe
return(poped_col)
}
f_ords<-function(train,freq=24,freqs,max_order){
train<-c(t(train)) # flatten train set
params<-expand.grid(lapply(freqs,function(x) seq(max_order))) # all combinations of fourier orders
aicc_best<-Inf # best aicc statistic
param_best<-NULL # best parameters
for (i in 1:nrow(params)){ # for each combination of orders
param<-unlist(params[i,]) # combination of orders
xreg_train<-fourier(msts(train,seasonal.periods=freqs),K=param) # fourier terms for particular multi-seasonal time series
fit=auto.arima(ts(train,frequency = freq),xreg=xreg_train,seasonal=FALSE,parallel = TRUE,stepwise=FALSE,approximation=FALSE) # find best arima model
if (fit$aicc<aicc_best){ # if there is an improvement in aicc statistic
param_best<-param # save these orders
aicc_best<-fit$aicc # save new best aicc value
}
print(param)
print(fit$aicc)
}
return(param_best)
}
arima<-function(train,test,hor=1,batch=7,freq=24,f_K=NULL,wxreg_train=NULL,wxreg_test=NULL,box_cox=FALSE,dec=FALSE){
test_pred<-data.frame(matrix(data=NA,nrow=nrow(test),ncol=ncol(test),dimnames=list(rownames(test),colnames(test))),check.names = FALSE) # initialize matrix for predictions
train<-c(t(train)) # flatten train set
test<-c(t(test)) # flatten test set
if (is.null(f_K)){ # not considering multiple seasonalities
fxreg_train<-NULL
fxreg_test<-NULL
}
else { # considering multiple seasonalities
fxreg_train<-fourier(msts(train,seasonal.periods=freqs),K=f_K)
fxreg_test<-fourier(msts(test,seasonal.periods=freqs),K=f_K)
}
if (is.null(wxreg_train)|is.null(wxreg_test)) # not considering weather regressors
{
wxreg_train<-NULL
wxreg_test<-NULL
}
else{ # considering weather regressors
wxreg_train<-do.call(cbind,lapply(wxreg_train,function(x) c(t(x)))) # flatten and combine weather regressors for train set
wxreg_test<-do.call(cbind,lapply(wxreg_test,function(x) c(t(x)))) # flatten and combine weather regressors for test set
}
xreg_train<-cbind(fxreg_train,wxreg_train) # combine fourier & weather into one matrix for train set
xreg_test<-cbind(fxreg_test,wxreg_test) # combine fourier & weather into one matrix for test set
xreg=NULL # default covariates
xreg_pred=NULL # default covariates for predictions
for (i in seq(0,length(test)-hor,hor)){ # for each window of observations in test set
train_ts<-ts(c(train,test[seq_len(i)]),frequency=freq) # add new observations from test set to the current train set
if (!is.null(xreg_train)&!is.null(xreg_test)){ # if considering external regressors
xreg<-rbind(xreg_train,xreg_test[seq_len(i),]) # add covariates corresponding to new observations
xreg_pred<-xreg_test[i+seq_len(hor),] # add covariates for predictions
}
if (i%%(batch*hor)==0){ # if its time to retrain
bc_lambda<-if (box_cox) BoxCox.lambda(train,method='') else NULL # estimate lambda for Box-Cox transformation
if (dec){ # if decomposition is to be applied
model<-stlm(train_ts,method='arima',xreg=xreg,s.window='periodic',robust=TRUE,parallel = TRUE,stepwise=FALSE,lambda=bc_lambda,biasadj = FALSE) # find best model on the current train set
cat(i%/%(batch*hor),arimaorder(model$model),'\n') # print number of retrainings and the type of model
}
else { # no decomposition
model<-auto.arima(train_ts,xreg=xreg,parallel = TRUE,stepwise=FALSE,lambda=bc_lambda,biasadj = FALSE) # find best model on the current train set
cat(i%/%(batch*hor),arimaorder(model),'\n') # print number of retrainings and the type of model
}
}
else{ # it is not the time to retrain
if (dec){
model<-stlm(train_ts,model=model,xreg=xreg,s.window='periodic',robust=TRUE,parallel = TRUE,stepwise=FALSE,lambda=bc_lambda,biasadj = FALSE) # do not train, use current model with new observations
}
else
{
model<-Arima(train_ts,model=model,xreg=xreg,lambda=bc_lambda,biasadj=FALSE) # do not train, use current model with new observations
}
}
test_pred[(i%/%hor)+1,]<-forecast(model,h=hor,lambda=bc_lambda,biasadj=FALSE)$mean # predict new values
}
return(test_pred)
}
arima_h<-function(train,test,batch=7,freq=48,f_K=NULL,wxreg_train=NULL,wxreg_test=NULL,box_cox=FALSE,dec=FALSE){
return(arima(train,test,hor=48,batch=batch,freq=freq,f_K=f_K,wxreg_train=wxreg_train,wxreg_test=wxreg_test,box_cox = box_cox,dec = dec))
}
arima_v<-function(train,test,batch=7,freq=7,f_K=NULL,wxreg_train=NULL,wxreg_test=NULL,box_cox=FALSE,dec=FALSE){
test_pred<-data.frame(matrix(data=NA,nrow=nrow(test),ncol=ncol(test),dimnames=list(rownames(test),colnames(test))),check.names = FALSE) # initialize dataframe for predictions
for (col in names(train)){
train_day<-as.data.frame(train[[col]],row.names=rownames(train)) # convert dataframe column to dataframe
test_day<-as.data.frame(test[[col]],row.names=rownames(test)) # convert dataframe column to dataframe
colnames(train_day)<-c(col) # set column name to match
colnames(test_day)<-c(col) # set column name to match
if (is.null(wxreg_train)|is.null(wxreg_test))
{
wxreg_train_day<-NULL
wxreg_test_day<-NULL
}
else
{
wxreg_train_day<-lapply(wxreg_train,function(x) as.data.frame(`[[`(x, col))) # extract a particular column from each member of list of covariates
wxreg_test_day<-lapply(wxreg_test,function(x) as.data.frame(`[[`(x, col))) # extract a particular column from each member of list of covariates
}
test_pred[[col]]<-arima(train_day,test_day,hor=1,batch=batch,freq=freq,f_K=f_K,wxreg_train=wxreg_train_day,wxreg_test=wxreg_test_day)[[col]] # predictions
}
return(test_pred)
}
data_dir<-'C:/Users/SABA/Google Drive/mtsg/data/nocb/arima/data/' # directory containing data
exp_dir<-'C:/Users/SABA/Google Drive/mtsg/data/nocb/arima/exp/' # directory for the results of experiments
train<-load(paste(data_dir,'train.csv', sep='')) # load train set
test<-load(paste(data_dir,'test.csv', sep='')) # load test set
test_pred_h<-arima_h(train,test,batch=7,freq=48) # predict values
?auto.arima
arima<-function(train,test,hor=1,batch=7,freq=24,f_K=NULL,wxreg_train=NULL,wxreg_test=NULL,box_cox=FALSE,dec=FALSE){
test_pred<-data.frame(matrix(data=NA,nrow=nrow(test),ncol=ncol(test),dimnames=list(rownames(test),colnames(test))),check.names = FALSE) # initialize matrix for predictions
train<-c(t(train)) # flatten train set
test<-c(t(test)) # flatten test set
if (is.null(f_K)){ # not considering multiple seasonalities
fxreg_train<-NULL
fxreg_test<-NULL
}
else { # considering multiple seasonalities
fxreg_train<-fourier(msts(train,seasonal.periods=freqs),K=f_K)
fxreg_test<-fourier(msts(test,seasonal.periods=freqs),K=f_K)
}
if (is.null(wxreg_train)|is.null(wxreg_test)) # not considering weather regressors
{
wxreg_train<-NULL
wxreg_test<-NULL
}
else{ # considering weather regressors
wxreg_train<-do.call(cbind,lapply(wxreg_train,function(x) c(t(x)))) # flatten and combine weather regressors for train set
wxreg_test<-do.call(cbind,lapply(wxreg_test,function(x) c(t(x)))) # flatten and combine weather regressors for test set
}
xreg_train<-cbind(fxreg_train,wxreg_train) # combine fourier & weather into one matrix for train set
xreg_test<-cbind(fxreg_test,wxreg_test) # combine fourier & weather into one matrix for test set
xreg=NULL # default covariates
xreg_pred=NULL # default covariates for predictions
for (i in seq(0,length(test)-hor,hor)){ # for each window of observations in test set
train_ts<-ts(c(train,test[seq_len(i)]),frequency=freq) # add new observations from test set to the current train set
if (!is.null(xreg_train)&!is.null(xreg_test)){ # if considering external regressors
xreg<-rbind(xreg_train,xreg_test[seq_len(i),]) # add covariates corresponding to new observations
xreg_pred<-xreg_test[i+seq_len(hor),] # add covariates for predictions
}
if (i%%(batch*hor)==0){ # if its time to retrain
bc_lambda<-if (box_cox) BoxCox.lambda(train,method='') else NULL # estimate lambda for Box-Cox transformation
if (dec){ # if decomposition is to be applied
model<-stlm(train_ts,method='arima',xreg=xreg,s.window='periodic',robust=TRUE,parallel = TRUE,stepwise=FALSE,lambda=bc_lambda,biasadj = FALSE) # find best model on the current train set
cat(i%/%(batch*hor),arimaorder(model$model),'\n') # print number of retrainings and the type of model
}
else { # no decomposition
model<-auto.arima(train_ts,xreg=xreg,lambda=bc_lambda,biasadj = FALSE,trace = TRUE) # find best model on the current train set
cat(i%/%(batch*hor),arimaorder(model),'\n') # print number of retrainings and the type of model
}
}
else{ # it is not the time to retrain
if (dec){
model<-stlm(train_ts,model=model,xreg=xreg,s.window='periodic',robust=TRUE,parallel = TRUE,stepwise=FALSE,lambda=bc_lambda,biasadj = FALSE) # do not train, use current model with new observations
}
else
{
model<-Arima(train_ts,model=model,xreg=xreg,lambda=bc_lambda,biasadj=FALSE) # do not train, use current model with new observations
}
}
test_pred[(i%/%hor)+1,]<-forecast(model,h=hor,lambda=bc_lambda,biasadj=FALSE)$mean # predict new values
}
return(test_pred)
}
data_dir<-'C:/Users/SABA/Google Drive/mtsg/data/nocb/arima/data/' # directory containing data
exp_dir<-'C:/Users/SABA/Google Drive/mtsg/data/nocb/arima/exp/' # directory for the results of experiments
train<-load(paste(data_dir,'train.csv', sep='')) # load train set
test<-load(paste(data_dir,'test.csv', sep='')) # load test set
test_pred_h<-arima_h(train,test,batch=7,freq=48) # predict values
?stlm
ets_w<-function(train,test,hor=48,batch=7,freq=48,box_cox=FALSE, dec=FALSE){
test_pred<-data.frame(matrix(data=NA,nrow=nrow(test),ncol=ncol(test),dimnames=list(rownames(test),colnames(test))),check.names = FALSE) # initialize dataframe for predictions
train<-c(t(train)) # flatten train set
test<-c(t(test)) # flatten test set
for (i in seq(0,length(test)-hor,hor)){ # for each sample in test set
train_ts<-ts(c(train,test[seq_len(i)]),frequency=freq) # add new observations from test set to the current train set
if (i%%(batch*hor)==0){ # # if its time to retrain
bc_lambda<-if (box_cox) BoxCox.lambda(train,method='guerrero') else NULL # estimate lambda for Box-Cox transformation
if (dec){
model<-stlm(train_ts,method='ets',allow.multiplicative.trend = TRUE,s.window='periodic',robust=TRUE,lambda=bc_lambda,biasadj=FALSE)
cat(i%/%(batch*hor),model$model$components,'\n') # print number of retrainings and the type of model
}
else{
model<-ets(train_ts,lambda=bc_lambda,biasadj=FALSE)
cat(i%/%(batch*hor),model$components,'\n') # print number of retrainings and the type of model
}
}
else{ # it is not the time to retrain
if (dec){
model<-stlm(train_ts,model=model,s.window='periodic',robust=TRUE,lambda=bc_lambda,biasadj=FALSE) # do not train, use current model with new observations
}
else{
model<-ets(train_ts,model=model,lambda=bc_lambda,biasadj=FALSE)
}
}
test_pred[(i%/%hor)+1,]<-forecast(model,h=hor,lambda=bc_lambda,biasadj=FALSE)$mean # predict new values
}
return(test_pred)
}
# DECOMPOSITION
data_dir<-'C:/Users/SABA/Google Drive/mtsg/data/nocb/' # directory containing data
exp_dir<-'C:/Users/SABA/Google Drive/mtsg/data/nocb/exp/ets/' # directory for the results of experiments
train<-load(path=paste(data_dir,'train.csv', sep=''),index='date') # load train set
test<-load(path=paste(data_dir,'test.csv', sep=''),index='date') # load test set
# horizontal prediction
test_pred_h<-ets_h(train,test,batch=7,freq=48,dec=TRUE) # predict values
data_dir<-'C:/Users/SABA/Google Drive/mtsg/data/nocb/ets/data/' # directory containing data
exp_dir<-'C:/Users/SABA/Google Drive/mtsg/data/nocb/ets/results/' # directory for the results of experiments
train<-load(path=paste(data_dir,'train.csv', sep=''),index='date') # load train set
test<-load(path=paste(data_dir,'test.csv', sep=''),index='date') # load test set
test_pred_h<-ets_h(train,test,batch=7,freq=48,dec=TRUE) # predict values
save(data=test_pred_h,path=paste(exp_dir,'dec,ets_h.csv',sep='')) # write results
# vertical predictions
test_pred_v<-ets_v(train,test,batch=7,freq=7,,dec=TRUE) # predict values
save(data=test_pred_v,path=paste(exp_dir,'dec,ets_v.csv',sep='')) # write results
# horizontal predictions for each day separately
for (i in 0:6){ # for each day
train<-load(paste(data_dir,'train_',i,'.csv', sep='')) # load train set
test<-load(paste(data_dir,'test_',i,'.csv', sep='')) # load test set
test_pred_hw<-ets_h(train,test,batch=1,freq=48,dec=TRUE) # horizontal predictions for this day
save(data=test_pred_hw,path=paste(exp_dir,'dec,ets_h_',i,'.csv',sep='')) # write results
}
# vertical predictions for each day separately
for (i in 0:6){ # for each day
train<-load(paste(data_dir,'train_',i,'.csv', sep='')) # load train set
test<-load(paste(data_dir,'test_',i,'.csv', sep='')) # load test set
test_pred_vw<-ets_v(train,test,batch=1,freq=52,dec=TRUE) # horizontal predictions for this day
save(data=test_pred_vw,path=paste(exp_dir,'dec,ets_v_',i,'.csv',sep='')) # write results
}
# DECOPMPOSITION + BOX COX
data_dir<-'C:/Users/SABA/Google Drive/mtsg/data/nocb/' # directory containing data
exp_dir<-'C:/Users/SABA/Google Drive/mtsg/data/nocb/exp/ets/' # directory for the results of experiments
train<-load(path=paste(data_dir,'train.csv', sep=''),index='date') # load train set
test<-load(path=paste(data_dir,'test.csv', sep=''),index='date') # load test set
# horizontal prediction
test_pred_h<-ets_h(train,test,batch=7,freq=48,box_cox = TRUE,dec=TRUE) # predict values
save(data=test_pred_h,path=paste(exp_dir,'dec,bc,ets_h.csv',sep='')) # write results
# vertical predictions
test_pred_v<-ets_v(train,test,batch=7,freq=7,box_cox = TRUE,dec=TRUE) # predict values
save(data=test_pred_v,path=paste(exp_dir,'dec,bc,ets_v.csv',sep='')) # write results
# horizontal predictions for each day separately
for (i in 0:6){ # for each day
train<-load(paste(data_dir,'train_',i,'.csv', sep='')) # load train set
test<-load(paste(data_dir,'test_',i,'.csv', sep='')) # load test set
test_pred_hw<-ets_h(train,test,batch=1,freq=48,box_cox = TRUE,dec=TRUE) # horizontal predictions for this day
save(data=test_pred_hw,path=paste(exp_dir,'dec,bc,ets_h_',i,'.csv',sep='')) # write results
}
# vertical predictions for each day separately
for (i in 0:6){ # for each day
train<-load(paste(data_dir,'train_',i,'.csv', sep='')) # load train set
test<-load(paste(data_dir,'test_',i,'.csv', sep='')) # load test set
test_pred_vw<-ets_v(train,test,batch=1,freq=4,box_cox = TRUE,dec=TRUE) # horizontal predictions for this day
save(data=test_pred_vw,path=paste(exp_dir,'dec,bc,ets_v_',i,'.csv',sep='')) # write results
}
data_dir<-'C:/Users/SABA/Google Drive/mtsg/data/nocb/ets/data/' # directory containing data
exp_dir<-'C:/Users/SABA/Google Drive/mtsg/data/nocb/ets/results/' # directory for the results of experiments
train<-load(path=paste(data_dir,'train.csv', sep=''),index='date') # load train set
test<-load(path=paste(data_dir,'test.csv', sep=''),index='date') # load test set
# horizontal prediction
test_pred_h<-ets_h(train,test,batch=7,freq=48,box_cox = TRUE,dec=TRUE) # predict values
save(data=test_pred_h,path=paste(exp_dir,'dec,bc,ets_h.csv',sep='')) # write results
# vertical predictions
test_pred_v<-ets_v(train,test,batch=7,freq=7,box_cox = TRUE,dec=TRUE) # predict values
save(data=test_pred_v,path=paste(exp_dir,'dec,bc,ets_v.csv',sep='')) # write results
# horizontal predictions for each day separately
for (i in 0:6){ # for each day
train<-load(paste(data_dir,'train_',i,'.csv', sep='')) # load train set
test<-load(paste(data_dir,'test_',i,'.csv', sep='')) # load test set
test_pred_hw<-ets_h(train,test,batch=1,freq=48,box_cox = TRUE,dec=TRUE) # horizontal predictions for this day
save(data=test_pred_hw,path=paste(exp_dir,'dec,bc,ets_h_',i,'.csv',sep='')) # write results
}
# vertical predictions for each day separately
for (i in 0:6){ # for each day
train<-load(paste(data_dir,'train_',i,'.csv', sep='')) # load train set
test<-load(paste(data_dir,'test_',i,'.csv', sep='')) # load test set
test_pred_vw<-ets_v(train,test,batch=1,freq=4,box_cox = TRUE,dec=TRUE) # horizontal predictions for this day
save(data=test_pred_vw,path=paste(exp_dir,'dec,bc,ets_v_',i,'.csv',sep='')) # write results
}
library(forecast)
source('dataprep.R')
pop_col=function(data,col){ # removes and returns column from dataframe
poped_col<-data$col # extract column from dataframe
data<<-data[ , !names(data) %in% c(col)] # drop column from dataframe
return(poped_col)
}
f_ords<-function(train,freq=24,freqs,max_order){
train<-c(t(train)) # flatten train set
params<-expand.grid(lapply(freqs,function(x) seq(max_order))) # all combinations of fourier orders
aicc_best<-Inf # best aicc statistic
param_best<-NULL # best parameters
for (i in 1:nrow(params)){ # for each combination of orders
param<-unlist(params[i,]) # combination of orders
xreg_train<-fourier(msts(train,seasonal.periods=freqs),K=param) # fourier terms for particular multi-seasonal time series
fit=auto.arima(ts(train,frequency = freq),xreg=xreg_train,seasonal=FALSE,parallel = TRUE,stepwise=FALSE,approximation=FALSE) # find best arima model
if (fit$aicc<aicc_best){ # if there is an improvement in aicc statistic
param_best<-param # save these orders
aicc_best<-fit$aicc # save new best aicc value
}
print(param)
print(fit$aicc)
}
return(param_best)
}
arima<-function(train,test,hor=1,batch=7,freq=24,f_K=NULL,wxreg_train=NULL,wxreg_test=NULL,box_cox=FALSE,dec=FALSE){
test_pred<-data.frame(matrix(data=NA,nrow=nrow(test),ncol=ncol(test),dimnames=list(rownames(test),colnames(test))),check.names = FALSE) # initialize matrix for predictions
train<-c(t(train)) # flatten train set
test<-c(t(test)) # flatten test set
if (is.null(f_K)){ # not considering multiple seasonalities
fxreg_train<-NULL
fxreg_test<-NULL
}
else { # considering multiple seasonalities
fxreg_train<-fourier(msts(train,seasonal.periods=freqs),K=f_K)
fxreg_test<-fourier(msts(test,seasonal.periods=freqs),K=f_K)
}
if (is.null(wxreg_train)|is.null(wxreg_test)) # not considering weather regressors
{
wxreg_train<-NULL
wxreg_test<-NULL
}
else{ # considering weather regressors
wxreg_train<-do.call(cbind,lapply(wxreg_train,function(x) c(t(x)))) # flatten and combine weather regressors for train set
wxreg_test<-do.call(cbind,lapply(wxreg_test,function(x) c(t(x)))) # flatten and combine weather regressors for test set
}
xreg_train<-cbind(fxreg_train,wxreg_train) # combine fourier & weather into one matrix for train set
xreg_test<-cbind(fxreg_test,wxreg_test) # combine fourier & weather into one matrix for test set
xreg=NULL # default covariates
xreg_pred=NULL # default covariates for predictions
for (i in seq(0,length(test)-hor,hor)){ # for each window of observations in test set
train_ts<-ts(c(train,test[seq_len(i)]),frequency=freq) # add new observations from test set to the current train set
if (!is.null(xreg_train)&!is.null(xreg_test)){ # if considering external regressors
xreg<-rbind(xreg_train,xreg_test[seq_len(i),]) # add covariates corresponding to new observations
xreg_pred<-xreg_test[i+seq_len(hor),] # add covariates for predictions
}
if (i%%(batch*hor)==0){ # if its time to retrain
bc_lambda<-if (box_cox) BoxCox.lambda(train,method='') else NULL # estimate lambda for Box-Cox transformation
if (dec){ # if decomposition is to be applied
model<-stlm(train_ts,method='arima',xreg=xreg,s.window='periodic',robust=TRUE,parallel = TRUE,stepwise=FALSE,lambda=bc_lambda,biasadj = FALSE) # find best model on the current train set
cat(i%/%(batch*hor),arimaorder(model$model),'\n') # print number of retrainings and the type of model
}
else { # no decomposition
model<-auto.arima(train_ts,xreg=xreg,lambda=bc_lambda,biasadj = FALSE,trace = TRUE) # find best model on the current train set
cat(i%/%(batch*hor),arimaorder(model),'\n') # print number of retrainings and the type of model
}
}
else{ # it is not the time to retrain
if (dec){
model<-stlm(train_ts,model=model,xreg=xreg,s.window='periodic',robust=TRUE,parallel = TRUE,stepwise=FALSE,lambda=bc_lambda,biasadj = FALSE) # do not train, use current model with new observations
}
else
{
model<-Arima(train_ts,model=model,xreg=xreg,lambda=bc_lambda,biasadj=FALSE) # do not train, use current model with new observations
}
}
test_pred[(i%/%hor)+1,]<-forecast(model,h=hor,lambda=bc_lambda,biasadj=FALSE)$mean # predict new values
}
return(test_pred)
}
arima_h<-function(train,test,batch=7,freq=48,f_K=NULL,wxreg_train=NULL,wxreg_test=NULL,box_cox=FALSE,dec=FALSE){
return(arima(train,test,hor=48,batch=batch,freq=freq,f_K=f_K,wxreg_train=wxreg_train,wxreg_test=wxreg_test,box_cox = box_cox,dec = dec))
}
arima_v<-function(train,test,batch=7,freq=7,f_K=NULL,wxreg_train=NULL,wxreg_test=NULL,box_cox=FALSE,dec=FALSE){
test_pred<-data.frame(matrix(data=NA,nrow=nrow(test),ncol=ncol(test),dimnames=list(rownames(test),colnames(test))),check.names = FALSE) # initialize dataframe for predictions
for (col in names(train)){
train_day<-as.data.frame(train[[col]],row.names=rownames(train)) # convert dataframe column to dataframe
test_day<-as.data.frame(test[[col]],row.names=rownames(test)) # convert dataframe column to dataframe
colnames(train_day)<-c(col) # set column name to match
colnames(test_day)<-c(col) # set column name to match
if (is.null(wxreg_train)|is.null(wxreg_test))
{
wxreg_train_day<-NULL
wxreg_test_day<-NULL
}
else
{
wxreg_train_day<-lapply(wxreg_train,function(x) as.data.frame(`[[`(x, col))) # extract a particular column from each member of list of covariates
wxreg_test_day<-lapply(wxreg_test,function(x) as.data.frame(`[[`(x, col))) # extract a particular column from each member of list of covariates
}
test_pred[[col]]<-arima(train_day,test_day,hor=1,batch=batch,freq=freq,f_K=f_K,wxreg_train=wxreg_train_day,wxreg_test=wxreg_test_day)[[col]] # predictions
}
return(test_pred)
}
data_dir<-'C:/Users/SABA/Google Drive/mtsg/data/nocb/arima/data/' # directory containing data
exp_dir<-'C:/Users/SABA/Google Drive/mtsg/data/nocb/arima/exp/' # directory for the results of experiments
train<-load(paste(data_dir,'train.csv', sep='')) # load train set
test<-load(paste(data_dir,'test.csv', sep='')) # load test set
test_pred_h<-arima_h(train,test,batch=7,freq=48) # predict values
save(data=test_pred_h,path=paste(exp_dir,'arima_h','.csv',sep='')) # write results
exp_dir<-'C:/Users/SABA/Google Drive/mtsg/data/nocb/arima/results/' # directory for the results of experiments
save(data=test_pred_h,path=paste(exp_dir,'arima_h','.csv',sep='')) # write results
