xreg
wxreg_train
xreg<-cbind(lapply(wxreg_train,function(x) c(t(x)))) # format and combine weather regressors for train set
xreg
?lapply
xreg.ismatrix()
xreg.is.matrix()
?is.matrix
xreg.is.matrix
is.matrix(xreg)
xreg[1,]
?do.call
?matrix
do.call(lapply(wxreg_train,function(x) c(t(x))))
?do.call
do.call(cbind,lapply(wxreg_train,function(x) c(t(x))))
xregs=list(temp_train,hum_train,wspd_train,prsr_train)
wxreg_train<-do.call(cbind,lapply(regs,function(x) c(t(x)))) # format and combine weather regressors for train set
wxreg_train<-do.call(cbind,lapply(xregs,function(x) c(t(x)))) # format and combine weather regressors for train set
wxreg_train
wxreg_train[1,]
wxreg_train[:10,]
wxreg_train[1:10,]
test
head(test,10)
test[1:10,]
test[1:0,]
test[1:1,]
1:0
1:0:1
?seq
head(test,0)
head[1:1]
head[1:0]
test[1:0,]
test[0:0,]
test[0:1,]
test[1:1,]
test[1:1,]
1:1
test[1:1,]
0:0
0:1
0:10:2
0:2:10
?seq
seq(0,10,2)
test
c(t(test))
nrow(c(t(test)))
len(c(t(test)))
NROW(c(t(test)))
length(c(t(test)))
8688/24
seq(0,8677,24)
seq(0,8688,24)
seq(0,8688-24,24)
seq(0,8688-1,24)
?seq
?length.out
?seq_len
seq(0,8688-24,24)
seq_len(0)
test
test[seq_len(0)]
test[0]
test[1]
test
c(t(test))[seq_len(0)]
c(t(test))[seq_len(1)]
c(t(test))[seq_len(2)]
c(t(test))[seq_len(24)]
c(t(test))[seq_len(24),]
seq_len(24)
seq_len(24)+24
cbind(NULL,NULL)
cbind(NULL,5)
?cbind
rbind(c(t(train)),c(t(test)))
c(c(t(train)),c(t(test)))
ts(c(c(t(train)),c(t(test))),grequency=24)
ts(c(c(t(train)),c(t(test))),frequency=24)
c(c(t(train)),c(t(test)))
train
length(train)
nrows(train)
nrow(train)
1078*24
train[1078,]
test[1,]
c(c(t(train)),c(t(test)))[(25872-24):25872+24]
c(c(t(train)),c(t(test)))[(25872-24):(25872+24)]
train[1077,]
c(c(t(train)),c(t(test))[seq_len(0)])
c(t(train))
train<-read.csv(paste(dir,'train.csv', sep=''),header=TRUE,row.names='date',sep=',',dec='.') # load train set
test<-read.csv(paste(dir,'test.csv', sep=''),header=TRUE,row.names='date',sep=',',dec='.') # load test set
temp_train<-read.csv(paste(dir,'train_tempm.csv', sep=''),header=TRUE,row.names='date',sep=',',dec='.') # load temperatures for train set
temp_test<-read.csv(paste(dir,'test_tempm.csv', sep=''),header=TRUE,row.names='date',sep=',',dec='.') # load temperatures for test set
hum_train<-read.csv(paste(dir,'train_hum.csv', sep=''),header=TRUE,row.names='date',sep=',',dec='.') # load humidities for train set
hum_test<-read.csv(paste(dir,'test_hum.csv', sep=''),header=TRUE,row.names='date',sep=',',dec='.') # load humidities for test set
wspd_train<-read.csv(paste(dir,'train_wspdm.csv', sep=''),header=TRUE,row.names='date',sep=',',dec='.') # load wind speeds for train set
wspd_test<-read.csv(paste(dir,'test_wspdm.csv', sep=''),header=TRUE,row.names='date',sep=',',dec='.') # load wind speeds for test set
prsr_train<-read.csv(paste(dir,'train_pressurem.csv', sep=''),header=TRUE,row.names='date',sep=',',dec='.') # load pressures for train set
prsr_test<-read.csv(paste(dir,'test_pressurem.csv', sep=''),header=TRUE,row.names='date',sep=',',dec='.') # load pressures for test set
xregs=list(temp_train,hum_train,wspd_train,prsr_train)
xregs_test=list(temp_test,hum_test,wspd_test,prsr_test)
K=c(10,6)
wxreg_train=list(temp_train,hum_train,wspd_train,prsr_train)
wxreg_test=list(temp_test,hum_test,wspd_test,prsr_test)
K=c(10,6)
batch=28
freq=24
f_K=K
wxreg_train=wxreg_train
wxreg_test=wxreg_train
train<-c(t(train)) # flatten train set
test<-c(t(test)) # flatten test set
is.null(f_K)
if (is.null(f_K)){ # not considering multiple seasonalities
fxreg_train<-NULL
fxreg_test<-NULL
}
else { # considering multiple seasonalities
fxreg_train<-fourier(msts(train,seasonal.periods=freqs),K=f_K)
fxreg_test<-fourier(msts(test,seasonal.periods=freqs),K=f_K)
}
fxreg_train<-fourier(msts(train,seasonal.periods=freqs),K=f_K)
library(forecast)
library(lubridate)
fxreg_train<-fourier(msts(train,seasonal.periods=freqs),K=f_K)
fxreg_test<-fourier(msts(test,seasonal.periods=freqs),K=f_K)
is.null(wxreg_train)|is.null(wxreg_test)
wxreg_train<-do.call(cbind,lapply(wxreg_train,function(x) c(t(x)))) # flatten and combine weather regressors for train set
wxreg_test<-do.call(cbind,lapply(wxreg_test,function(x) c(t(x)))) # flatten and combine weather regressors for test set
wxreg_train=list(temp_train,hum_train,wspd_train,prsr_train)
wxreg_test=list(temp_test,hum_test,wspd_test,prsr_test)
wxreg_train_c<-do.call(cbind,lapply(wxreg_train,function(x) c(t(x)))) # flatten and combine weather regressors for train set
wxreg_test_c<-do.call(cbind,lapply(wxreg_test,function(x) c(t(x)))) # flatten and combine weather regressors for test set
wxreg_train<-do.call(cbind,lapply(wxreg_train,function(x) c(t(x)))) # flatten and combine weather regressors for train set
wxreg_test<-do.call(cbind,lapply(wxreg_test,function(x) c(t(x)))) # flatten and combine weather regressors for test set
xreg_train<-cbind(fxreg_train,wxreg_train) # combine fourier & weather into one matrix for train set
xreg_test<-cbind(fxreg_test,wxreg_test) # combine fourier & weather into one matrix for test set
dim(fxreg_train)
dim(fxreg_test)
test_pred<-data.frame(matrix(data=NA,nrow=nrow(test),ncol=ncol(test),dimnames=list(rownames(test),colnames(test)))) # initialize matrix for predictions
train<-read.csv(paste(dir,'train.csv', sep=''),header=TRUE,row.names='date',sep=',',dec='.') # load train set
test<-read.csv(paste(dir,'test.csv', sep=''),header=TRUE,row.names='date',sep=',',dec='.') # load test set
test_pred<-data.frame(matrix(data=NA,nrow=nrow(test),ncol=ncol(test),dimnames=list(rownames(test),colnames(test)))) # initialize matrix for predictions
train<-c(t(train)) # flatten train set
test<-c(t(test)) # flatten test set
seq(0,length(test)-h,h)
h
seq(0,length(test)-hor,hor)
i=0
train_ts<-ts(c(train,test[seq_len(i)]),frequency=freq) # add new observations from test set to the current train set
!is.null(xreg_train)&!is.null(xreg_test)
i%%batch==0
xreg=NULL # default covariances
model<-auto.arima(train_ts,xreg=xreg) # find best model on the current train set
?Arima
model<-auto.arima(train_ts,xreg=xreg,seasonal=FALSE,parallel = TRUE,stepwise=FALSE) # find best model on the current train set
xreg
xreg<-rbind(xreg_train,xreg_test[seq_len(i),]) # add covariates corresponding to new observations
xreg_pred<-xreg_test[i+seq_len(hor),] # add covariates for predictions
model<-auto.arima(train_ts,xreg=xreg,seasonal=FALSE,parallel = TRUE,stepwise=FALSE) # find best model on the current train set
test_list=list(list(a=1,b=2),list(a=3,b=4))
sapply(test_list,`[[`,"a")
sapply(test_list,X = `,"a")
sapply(test_list,`$`,"a")
sapply(test_list,`[[`,"a")
lapply(wxreg_train,`[[`,0)
lapply(wxreg_train,`[[`,1)
colnames(wxreg_train)
names(wxreg_train)
wxreg_train=list(temp_train,hum_train,wspd_train,prsr_train)
names(wxreg_train)
names(train)
train
train<-read.csv(paste(dir,'train.csv', sep=''),header=TRUE,row.names='date',sep=',',dec='.') # load train set
test<-read.csv(paste(dir,'test.csv', sep=''),header=TRUE,row.names='date',sep=',',dec='.') # load test set
names(train)
lapply(wxreg_train,`[[`,"X0")
test_list<-lapply(wxreg_train,`[[`,"X0")
test_list[1]
is.data.frame(test_list[1])
is.vector(test_list[1])
test_list<-lapply(wxreg_train,function(x) as.data.frame(`[[`,x),"X0")
train
`[[` train 'X0'
`[[`(train, 'X0')
test_list<-lapply(wxreg_train,function(x) as.data.frame(`[[`(x,'X0')))
test_list
wxreg_train
wxreg_train<-lapply(wxreg_train,function(x) as.data.frame(`[[`(x, col))) # extract a particular column from each member of list of covariates
names(train)
wxreg_train<-lapply(wxreg_train,function(x) as.data.frame(`[[`(x, 'X0'))) # extract a particular column from each member of list of covariates
wxreg_train<-do.call(cbind,lapply(wxreg_train,function(x) c(t(x)))) # flatten and combine weather regressors for train set
View(wxreg_train)
nrows(train)
nrow(train)
load<-function(path){
data<-read.csv(path,header=TRUE,row.names='date',sep=',',dec='.') # load data
return(data)
}
train<-load(paste(dir,'train.csv', sep='')) # load train set
train
wxregs_train<-lapply(list('train_tempm.csv','train_hum.csv','train_wspdm.csv','train_pressurem.csv'),function(x) load(paste(dir,x,sep='')))
wxregs_test<-lapply(list('test_tempm.csv','test_hum.csv','test_wspdm.csv','test_pressurem.csv'),function(x) load(paste(dir,x,sep='')))
train<-load(paste(dir,'train.csv', sep='')) # load train set
test<-load(paste(dir,'test.csv', sep='')) # load test set
library(forecast)
library(lubridate)
K<-f_ords(train,freq=24,freqs=c(24*7,365.25*7),max_order=10) # find best fourier coefficients
f_ords<-function(train,freq=24,freqs,max_order){
train<-c(t(train)) # flatten train set
params<-expand.grid(lapply(freqs,function(x) seq(max_order))) # all combinations of fourier orders
aicc_best<-Inf # best aicc statistic
param_best<-NULL # best parameters
for (i in 1:nrow(params)){ # for each combination of orders
param<-unlist(params[i,]) # combination of orders
xreg_train<-fourier(msts(train,seasonal.periods=freqs),K=param) # fourier terms for particular multi-seasonal time series
fit=auto.arima(ts(train,frequency = freq),xreg=xreg_train,seasonal=FALSE,parallel = TRUE,stepwise=FALSE) # find best arima model
if (fit$aicc<aicc_best){ # if there is an improvement in aicc statistic
param_best<-param # save these orders
aicc_best<-fit$aicc # save new best aicc value
}
print(param)
print(fit$aicc)
}
return(param_best)
}
K<-f_ords(train,freq=24,freqs=c(24*7,365.25*7),max_order=10) # find best fourier coefficients
K
source('dataprep')
source('dataprep.R')
source('dataprep.R')
48%/%24
library(forecast)
source('dataprep.R')
dir='C:/Users/SABA/Google Drive/mtsg/data/' # directory containing data
train<-load(paste(dir,'train.csv', sep='')) # load train set
test<-load(paste(dir,'test.csv', sep='')) # load test set
test_pred<-data.frame(matrix(data=NA,nrow=nrow(test),ncol=ncol(test),dimnames=list(rownames(test),colnames(test)))) # initialize matrix for predictions
train<-c(t(train)) # flatten train set
test<-c(t(test)) # flatten test set
i=0
train_ts<-ts(c(train,test[seq_len(i)]),frequency=freq) # add new observations from test set to the current train set
model=ets(test_ts) # find best model on the current train set
test_pred[(i%/%hor)+1,]=forecast(model,h=hor)$mean # predict new values
test_pred
?msts
?bats
dir='C:/Users/SABA/Google Drive/mtsg/data/' # directory containing data
train<-load(paste(dir,'train.csv', sep='')) # load train set
test<-load(paste(dir,'test.csv', sep='')) # load test set
test_pred<-data.frame(matrix(data=NA,nrow=nrow(test),ncol=ncol(test),dimnames=list(rownames(test),colnames(test)))) # initialize matrix for predictions
train<-c(t(train)) # flatten train set
test<-c(t(test)) # flatten test set
i=0
train_ts<-msts(c(train,test[seq_len(i)]),seasonal.periods=freq) # add new observations from test set to the current train set
model=bats(test_ts,use.parallel=TRUE) # find best model on the current train set
model
test_pred[(i%/%hor)+1,]=forecast(model,h=hor)$mean # predict new values
f_ords<-function(train,freq=24,freqs,max_order){
train<-c(t(train)) # flatten train set
params<-expand.grid(lapply(freqs,function(x) seq(max_order))) # all combinations of fourier orders
aicc_best<-Inf # best aicc statistic
param_best<-NULL # best parameters
for (i in 1:nrow(params)){ # for each combination of orders
param<-unlist(params[i,]) # combination of orders
xreg_train<-fourier(msts(train,seasonal.periods=freqs),K=param) # fourier terms for particular multi-seasonal time series
fit=auto.arima(ts(train,frequency = freq),xreg=xreg_train,seasonal=FALSE,parallel = TRUE,stepwise=FALSE) # find best arima model
if (fit$aicc<aicc_best){ # if there is an improvement in aicc statistic
param_best<-param # save these orders
aicc_best<-fit$aicc # save new best aicc value
}
print(param)
print(fit$aicc)
}
return(param_best)
}
K=c(10)
K<-f_ords(train,freq=365.25,freqs=c(7),max_order=20) # find best fourier coefficients
7/2
K<-f_ords(train,freq=365.25,freqs=c(7),max_order=3) # find best fourier coefficients
K
data_dir='C:/Users/SABA/Google Drive/mtsg/data/wip/' # directory containing data
exp_dir='C:/Users/SABA/Google Drive/mtsg/data/experiments/' # directory containing data
?write.csv
train<-load(paste(wip_dir,'train.csv', sep='')) # load train set
wip_dir='C:/Users/SABA/Google Drive/mtsg/data/wip/' # directory containing data
exp_dir='C:/Users/SABA/Google Drive/mtsg/data/experiments/' # directory for the results of experiments
train<-load(paste(wip_dir,'train.csv', sep='')) # load train set
test<-load(paste(wip_dir,'test.csv', sep='')) # load test set
test_pred<-data.frame(matrix(data=NA,nrow=nrow(test),ncol=ncol(test),dimnames=list(rownames(test),colnames(test)))) # initialize matrix for predictions
rownames(test_pred)
write.csv(test_pred,file=paste(exp_dir,'test','.csv',sep=''),quote = FALSE) # write predictions
write.csv(test_pred,file=paste(exp_dir,'test','.csv',sep=''),quote = FALSE,row.names=TRUE) # write predictions
write.csv(test_pred,file=paste(exp_dir,'test','.csv',sep=''),quote = FALSE,row.names=''date) # write predictions
write.csv(test_pred,file=paste(exp_dir,'test','.csv',sep=''),quote = FALSE,row.names=TRUE,col.names=TRUE) # write predictions
?write.table
?cbind
train
cbind(rownames(test),test)
cbind(date=rownames(test),test)
save(test_pred,paste(exp_dir,'test','.csv',sep=''))
source('dataprep.R')
save(test_pred,paste(exp_dir,'test','.csv',sep=''))
save(test_pred,paste(exp_dir,'test','.csv',sep=''))
source('dataprep.R')
save(test_pred,paste(exp_dir,'test','.csv',sep=''))
source('dataprep.R')
save(test_pred,paste(exp_dir,'test','.csv',sep=''))
?get
?assign
index='date'
eval(index)
eval(parse(text='index'))
?as.name
as.name('date')
as.name(index)
source('dataprep.R')
do.call
?do.call
?echo
as.name(index)=rownames(test)
as.name(index)
?assign
assign(index,rownames(test))
date
cbind(index,test)
cbind(as.name(index),test)
cbind(get(index),test)
source('dataprep.R')
save(test_pred,paste(exp_dir,'test','.csv',sep=''))
?cbind
write.csv(data.frame('date'=rownames(test_pred),test_pred),file=paste(exp_dir,'test.csv'),quote = FALSE,row.names=FALSE) # write predictions
write.csv(data.frame('date'=rownames(test_pred),test_pred),file=paste(exp_dir,'test.csv',sep=''),quote = FALSE,row.names=FALSE) # write predictions
?sink
library(forecast)
source('dataprep.R')
ets_w<-function(train,test,hor=1,batch=7,freq=7){
pb<-txtProgressBar(min = 0, max = nrow(test), style = 3) # initialize progress bar
test_pred<-data.frame(matrix(data=NA,nrow=nrow(test),ncol=ncol(test),dimnames=list(rownames(test),colnames(test)))) # initialize matrix for predictions
train<-c(t(train)) # flatten train set
test<-c(t(test)) # flatten test set
for (i in seq(0,length(test)-hor,hor)){ # for each sample in test set
train_ts<-ts(c(train,test[seq_len(i)]),frequency=freq) # add new observations from test set to the current train set
if (i%%batch==0){ # # if its time to retrain
model<-ets(test_ts) # find best model on the current train set
}
else{ # it is not the time to retrain
model<-ets(test_ts,model=model) # do not train, use current model with new observations
}
test_pred[(i%/%hor)+1,]<-forecast(model,h=hor)$mean # predict new values
setTxtProgressBar(pb, i) # update progress
}
close(pb) # close progress bar
return(data.frame(test_pred))
}
ets_h<-function(train,test,batch=7,freq=24){
return(ets_w(train,test,hor=24,batch=batch,freq=freq))
}
ets_v<-function(train,test,batch=7,freq=7){
test_pred<-as.data.frame(lapply(test, function(x) rep.int(NA, length(x)))) # template dataframe for predictions
for (col in names(train)){
train_day<-as.data.frame(train[[col]]) # convert dataframe column to dataframe
test_day<-as.data.frame(test[[col]]) # convert dataframe column to dataframe
colnames(train_day)<-c(col) # set column name to match
colnames(test_day)<-c(col) # set column name to match
test_pred[[col]]<-ets_w(train_day,test_day,hor=1,batch=batch,freq=freq) # predictions
}
return(test_pred)
}
wip_dir<-'C:/Users/SABA/Google Drive/mtsg/data/wip/' # directory containing data
exp_dir<-'C:/Users/SABA/Google Drive/mtsg/data/experiments/' # directory for the results of experiments
train<-load(paste(wip_dir,'train.csv', sep='')) # load train set
test<-load(paste(wip_dir,'test.csv', sep='')) # load test set
hor=24
batch=28
freq=24
test_pred<-data.frame(matrix(data=NA,nrow=nrow(test),ncol=ncol(test),dimnames=list(rownames(test),colnames(test)))) # initialize matrix for predictions
train<-c(t(train)) # flatten train set
test<-c(t(test)) # flatten test set
i=0
train_ts<-ts(c(train,test[seq_len(i)]),frequency=freq) # add new observations from test set to the current train set
if (i%%batch==0){ # # if its time to retrain
model<-ets(test_ts) # find best model on the current train set
}
model<-ets(test_ts) # find best model on the current train set
model
model$components
model$residuals
model$states
model$sigma2
model$sigma2
model$components
print(model$components)
library('forecast')
library('tcltk')
pb <- tkProgressBar(title = "progress bar", min = 0,
max = total, width = 300)
pb <- tkProgressBar(title = "progress bar", min = 0,
max = 10, width = 300)
setTkProgressBar(pb, 1, label=paste( round(1/total*100, 0),
"% done"))
setTkProgressBar(pb, 1, label=paste( round(1/10*100, 0),
"% done"))
total <- 20
# create progress bar
pb <- tkProgressBar(title = "progress bar", min = 0,
max = total, width = 300)
for(i in 1:total){
Sys.sleep(0.1)
setTkProgressBar(pb, i, label=paste( round(i/total*100, 0),
"% done"))
}
close(pb)
total <- 100
# create progress bar
pb <- tkProgressBar(title = "progress bar", min = 0,
max = total, width = 300)
for(i in 1:total){
Sys.sleep(0.1)
setTkProgressBar(pb, i, label=paste( round(i/total*100, 0),
"% done"))
}
close(pb)
total <- 100
# create progress bar
pb <- tkProgressBar(title = "ETS", min = 0,
max = total, width = 300)
for(i in 1:total){
Sys.sleep(0.1)
setTkProgressBar(pb, i, label=paste( round(i/total*100, 0),
"% done"))
}
close(pb)
total <- 100
# create progress bar
pb <- tkProgressBar(title = "ETS", min = 0,
max = total, width = 1000)
for(i in 1:total){
Sys.sleep(0.1)
setTkProgressBar(pb, i, label=paste( round(i/total*100, 0),
"% done"))
}
close(pb)
total <- 100
# create progress bar
pb <- tkProgressBar(title = "ETS", min = 0,
max = total, width = 500)
for(i in 1:total){
Sys.sleep(0.1)
setTkProgressBar(pb, i, label=paste( round(i/total*100, 0),
"% done"))
}
close(pb)
wip_dir='C:/Users/SABA/Google Drive/mtsg/data/wip/' # directory containing data
exp_dir='C:/Users/SABA/Google Drive/mtsg/data/experiments/' # directory for the results of experiments
# NO EXTERNAL REGRESSORS
train<-load(paste(wip_dir,'train.csv', sep='')) # load train set
test<-load(paste(wip_dir,'test.csv', sep='')) # load test set
test_pred<-data.frame(matrix(data=NA,nrow=nrow(test),ncol=ncol(test),dimnames=list(rownames(test),colnames(test)))) # initialize matrix for predictions
train<-c(t(train)) # flatten train set
freq=24
hor=24
batch=28
test_pred<-data.frame(matrix(data=NA,nrow=nrow(test),ncol=ncol(test),dimnames=list(rownames(test),colnames(test)))) # initialize matrix for predictions
train<-c(t(train)) # flatten train set
test<-c(t(test)) # flatten test set
xreg=NULL # default covariates
xreg_pred=NULL # default covariates for predictions
wxreg_train=NULL
wxreg_test=NULL
wxreg_train<-NULL
wxreg_test<-NULL
xreg_train<-cbind(fxreg_train,wxreg_train) # combine fourier & weather into one matrix for train set
xreg_test<-cbind(fxreg_test,wxreg_test) # combine fourier & weather into one matrix for test set
fxreg_train<-NULL
fxreg_test<-NULL
xreg_train<-cbind(fxreg_train,wxreg_train) # combine fourier & weather into one matrix for train set
xreg_test<-cbind(fxreg_test,wxreg_test) # combine fourier & weather into one matrix for test set
i=0
train_ts<-ts(c(train,test[seq_len(i)]),frequency=freq) # add new observations from test set to the current train set
model<-auto.arima(train_ts,xreg=xreg,seasonal=FALSE,parallel = TRUE,stepwise=FALSE) # find best model on the current train set
model
arimaorder(model)
freq
batch
hor
wip_dir='C:/Users/SABA/Google Drive/mtsg/data/wip/' # directory containing data
exp_dir='C:/Users/SABA/Google Drive/mtsg/data/experiments/' # directory for the results of experiments
train<-load(paste(wip_dir,'train.csv', sep='')) # load train set
test<-load(paste(wip_dir,'test.csv', sep='')) # load test set
batch=28
freqs=c(24,7*24,365.25*24)
hor=24
train<-c(t(train)) # flatten train set
test<-c(t(test)) # flatten test set
test_pred<-data.frame(matrix(data=NA,nrow=nrow(test),ncol=ncol(test),dimnames=list(rownames(test),colnames(test)))) # initialize matrix for predictions
test
train<-load(paste(wip_dir,'train.csv', sep='')) # load train set
test<-load(paste(wip_dir,'test.csv', sep='')) # load test set
test_pred<-data.frame(matrix(data=NA,nrow=nrow(test),ncol=ncol(test),dimnames=list(rownames(test),colnames(test)))) # initialize matrix for predictions
train<-c(t(train)) # flatten train set
test<-c(t(test)) # flatten test set
i
model=bats(test_ts,use.parallel=TRUE) # find best model on the current train set
model
?match.fun
